{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.contrib.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulation_data_generate as sdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple situation\n",
    "# just one kind of cell\n",
    "\n",
    "# x -- RNAseq, y -- ATACseq\n",
    "# x1,y2 true data, x2,y1 false data\n",
    "# x1 -> y1 G:generator, Dy:discriminator\n",
    "# y2 -> x1 F:generator, Dx:discriminator\n",
    "\n",
    "# input data\n",
    "data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scRAP(object):\n",
    "    \"\"\"\n",
    "    a simple situation version\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(m,n,learning_rate):\n",
    "        self._m = m\n",
    "        self._n = n\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    @staticmethod\n",
    "    def lrelu(x,alpha=0.2):\n",
    "        with tf.variable_scope('leakyRelu'):\n",
    "            return tf.maximum(x,alpha*x)\n",
    "    \n",
    "    # generator G\n",
    "    def G(self,Z,dim_Z):\n",
    "        with tf.variable_scope(\"G\"):\n",
    "            \n",
    "            dim_1 = 2*dim_z\n",
    "            dim_2 = 2*self._n\n",
    "            dim_3 = self._n\n",
    "            \n",
    "            W1 = tf.get_variable(\"G_W1\",shape=[dim_Z,dim_1],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W2 = tf.get_variable(\"G_W2\",shape=[dim_1,dim_2],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W3 = tf.get_variable(\"G_W3\",shape=[dim_2,dim_3],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            B1 = tf.get_variable(\"G_B1\",shape=[dim_1],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B2 = tf.get_variable(\"G_B2\",shape=[dim_2],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B3 = tf.get_variable(\"G_B3\",shape=[dim_3],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            \n",
    "            fc1 = self.lrelu(tf.add(tf.matmul(Z,W1)+B1))\n",
    "            fc2 = self.lrelu(tf.add(tf.matmul(fc1,W2)+B2))\n",
    "            fc3 = tf.nn.sigmoid(tf.add(tf.matmul(fc2,W3)+B3))\n",
    "            return fc3\n",
    "        \n",
    "    # generator F\n",
    "    def F(self,Z,dim_Z):\n",
    "        with tf.variable_scope(\"F\"):\n",
    "            \n",
    "            dim_1 = 2*dim_Z\n",
    "            dim_2 = 2*self._m\n",
    "            dim_3 = self._m\n",
    "            \n",
    "            W1 = tf.get_variable(\"F_W1\",shape=[dim_Z,dim_1],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W2 = tf.get_variable(\"F_W2\",shape=[dim_1,dim_2],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W3 = tf.get_variable(\"F_W3\",shape=[dim_2,dim_3],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            B1 = tf.get_variable(\"F_B1\",shape=[dim_1],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B2 = tf.get_variable(\"F_B2\",shape=[dim_2],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B3 = tf.get_variable(\"F_B3\",shape=[dim_3],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            \n",
    "            fc1 = self.lrelu(tf.add(tf.matmul(Z,W1)+B1))\n",
    "            fc2 = tf.nn.sigmoid(tf.add(tf.matmul(fc1,W2)+B2))\n",
    "            fc3 = tf.add(tf.matmul(fc2,W3)+B3)\n",
    "            return fc3\n",
    "    \n",
    "    # discriminator Dy\n",
    "    def Dy(self,Y):\n",
    "        with tf.variable_scope(\"Dy\"):\n",
    "            \n",
    "            dim_1 = self._n//2\n",
    "            dim_2 = self._n//4\n",
    "            dim_3 = 1\n",
    "            \n",
    "            W1 = tf.get_variable(\"Dy_W1\",shape=[dim_Z,dim_1],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W2 = tf.get_variable(\"Dy_W2\",shape=[dim_1,dim_2],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W3 = tf.get_variable(\"Dy_W3\",shape=[dim_2,dim_3],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            B1 = tf.get_variable(\"Dy_B1\",shape=[dim_1],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B2 = tf.get_variable(\"Dy_B2\",shape=[dim_2],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B3 = tf.get_variable(\"Dy_B3\",shape=[dim_3],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            \n",
    "            fc1 = self.lrelu(tf.add(tf.matmul(Y,W1)+B1))\n",
    "            fc2 = tf.nn.sigmoid(tf.add(tf.matmul(fc1,W2)+B2))\n",
    "            fc3 = tf.add(tf.matmul(fc2,W3)+B3)\n",
    "            return fc3,tf.nn.sigmoid(fc3)\n",
    "        \n",
    "     # discriminator Dx\n",
    "    def Dx(self,X):\n",
    "        with tf.variable_scope(\"Dy\"):\n",
    "            \n",
    "            dim_1 = self._m//2\n",
    "            dim_2 = self._m//4\n",
    "            dim_3 = 1\n",
    "            \n",
    "            W1 = tf.get_variable(\"Dx_W1\",shape=[dim_Z,dim_1],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W2 = tf.get_variable(\"Dx_W2\",shape=[dim_1,dim_2],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            W3 = tf.get_variable(\"Dx_W3\",shape=[dim_2,dim_3],\n",
    "                                 dtype=tf.float32,initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "            B1 = tf.get_variable(\"Dx_B1\",shape=[dim_1],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B2 = tf.get_variable(\"Dx_B2\",shape=[dim_2],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            B3 = tf.get_variable(\"Dx_B3\",shape=[dim_3],dtype=tf.float32,initializer=tf.constant_initializer())\n",
    "            \n",
    "            fc1 = self.lrelu(tf.add(tf.matmul(X,W1)+B1))\n",
    "            fc2 = tf.nn.sigmoid(tf.add(tf.matmul(fc1,W2)+B2))\n",
    "            fc3 = tf.add(tf.matmul(fc2,W3)+B3)\n",
    "            return fc3,tf.nn.sigmoid(fc3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data,batch_size):\n",
    "    input_queue = tf.train.slice_input_producer([data], num_epochs=1, shuffle=True, capacity=32 ) \n",
    "    batch = tf.train.batch(input_queue, batch_size=batch_size, num_threads=1, capacity=32, allow_smaller_final_batch=False)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,m,n,learning_rate,batch_size,lamda):\n",
    "    data_x = data[\"x\"]\n",
    "    data_y = data[\"y\"]\n",
    "    func = scRAP(m,n)\n",
    "    \n",
    "    with tf.variable_scope(\"placeholder\"):\n",
    "#         Z_x = tf.placeholder(tf.float32,[None,m])\n",
    "#         Z_y = tf.placeholder(tf.float32,[None,n])\n",
    "        X = tf.placeholder(tf.float32,[None,m])\n",
    "        Y = tf.placeholder(tf.float32,[None,n])\n",
    "        \n",
    "    with tf.variable_scope(\"cycGAN\"):\n",
    "        false_y = func.G(X,m)\n",
    "        false_x = func.F(Y,n)\n",
    "        false_y_x = func.F(false_y,n)\n",
    "        false_x_y = func.G(false_x,m)\n",
    "        false_Dy_logit, false_Dy_prob = func.Dy(false_y)\n",
    "        real_Dy_logit, real_Dy_prob = func.Dy(Y)\n",
    "        false_Dx_logit, false_Dx_prob = func.Dx(false_x)\n",
    "        real_Dx_logit, real_Dx_prob = func.Dx(X)\n",
    "        \n",
    "    with tf.variable_scope(\"gan_loss\"):\n",
    "        G_loss = lamda*tf.reduce_mean(tf.square(false_y_x-X))+lamda*tf.reduce_mean(\n",
    "            tf.square(false_x_y-Y))+tf.reduce_mean(tf.square(false_Dy_prob-1))\n",
    "        F_loss = lamda*tf.reduce_mean(tf.square(false_y_x-X))+lamda*tf.reduce_mean(\n",
    "            f.square(false_x_y-Y))+tf.reduce_mean(tf.square(false_Dx_prob-1))\n",
    "        Dy_loss = tf.reduce_mean(tf.square(real_Dy_prob-1))+tf.reduce_mean(tf.square(false_Dy_prob))\n",
    "        Dx_loss = tf.reduce_mean(tf.square(real_Dx_prob-1))+tf.reduce_mean(tf.square(false_Dx_prob))\n",
    "        \n",
    "    with tf.Variable_scope(\"train\"):\n",
    "        G_step = tf.train.AdamOptimizer(learning_rate).minimize(G_loss)\n",
    "        F_step = tf.train.AdamOptimizer(learning_rate).minimize(F_loss)\n",
    "        Dy_step = tf.train.AdamOptimizer(learning_rate).minimize(Dy_loss)\n",
    "        Dx_step = tf.train.AdamOptimizer(learning_rate).minimize(Dx_loss)\n",
    "        \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    x_batch = get_batch(data[\"x\"])\n",
    "    y_batch = get_batch(data[\"y\"])\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        for i in range(1000):\n",
    "            data_x, data_y = sess.run([x_batch,y_batch])\n",
    "            _, gloss = sess.run([G_step,G_loss],feed_dict={X:data_x,Y:data_y})\n",
    "            _, floss = sess.run([F_step,F_loss],feed_dict={X:data_x,Y:data_y})\n",
    "            _, dyloss = sess.run([Dy_step,Dy_loss],feed_dict={X:data_x,Y:data_y})\n",
    "            _, dxloss = sess.run([Dx_step,Dx_loss],feed_dict={X:data_x,Y:data_y})\n",
    "            if i % 10 == 0:\n",
    "                print(\"Epoch:{5},Gloss:{1},Floss:{2},Dyloss:{3},Dxloss:{4}\".format(gloss,floss,dyloss,dxloss,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
